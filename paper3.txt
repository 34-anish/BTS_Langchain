           Gracenote.ai: Legal Generative AI for Regulatory Compliance
Jules Ioannidis, Joshua Harper, Ming Sheng Quah 1 and Dan Hunter 1, 2
1
    Gracenote.ai, Melbourne Australia
2
    The Dickson Poon School of Law, King’s College London, United Kingdom*


                                Abstract: We investigate the transformative potential of large language models
                                (LLMs) in the legal and regulatory compliance domain by developing advanced
                                generative AI solutions, including a horizon scanning tool, an obligations generation
                                tool, and an LLM-based expert system. Our approach combines the LangChain
                                framework, OpenAI’s GPT-4, text embeddings, and prompt engineering techniques
                                to effectively reduce hallucinations and generate reliable and accurate domain-
                                specific outputs. A human-in-the-loop control mechanism is used as a final backstop
                                to ensure accuracy and mitigate risk. Our findings emphasise the role of LLMs as
                                foundation engines in specialist tools and lay the groundwork for building the next
                                generation of legal and compliance applications. Future research will focus on
                                extending support across multiple jurisdictions and languages, refining prompts and
                                text embedding datasets for enhanced legal reasoning capabilities, and developing
                                autonomous AI agents and robust LLM-based expert systems.

                                Keywords: AutoGPT, compliance, expert systems, GPT-4, GRC, LangChain, large
                                language models, legal generative AI, legal text embeddings, prompt engineering,
                                regulation
1

                                                                                                                   LLMs are often called “foundation models”
1. Introduction                                                                                                because they can be used as a foundation to drive
                                                                                                               a range of products and services. This can be done
                                                                                                               in several ways, but the two standard approaches
   Law relies on language. So, it’s hardly                                                                     involve prompt engineering and fine-tuning. Fine-
surprising that the development of large language
                                                                                                               tuning involves adapting a pre-trained LLM to a
models (LLMs) and the explosion of interest in                                                                 specific task or domain by training it on a
publicly accessible LLMs such as ChatGPT has
                                                                                                               specialised dataset, thus enhancing its relevance
led to the proliferation of papers about the use of                                                            and performance [11]. Although the providers of
these kinds of models in law. These papers                                                                     LLMs will often create interfaces for users to fine-
include some general explorations of natural                                                                   tune the model, fine-tuning is relatively difficult
language parsing and LLMs in law [1], [2], [3], as                                                             because it requires significant data and advanced
well as a number looking at whether GPT can pass                                                               skills at controlling the dataset to tune the pre-
the bar exam, law school exams, or other                                                                       trained model. A more common way of using
standardised legal tests [4], [5], [6], [7], and [8].                                                          LLMs as a foundation engine is to use prompt
Inevitably, there have been papers foretelling the                                                             engineering to constrain the output generated by
death of lawyers by LLMs [9], together with those
                                                                                                               the model.
which argue that the future of all professional
work will be revolutionised by LLMs [10].                                                                         LLMs rely on user-generated prompts to
                                                                                                               provide both the context and the request that
                                                                                                               generates the output (often called the

In: Proceedings of the Third International Workshop on Artificial
Intelligence and Intelligent Assistance for Legal Professionals in
the Digital Workplace (LegalAIIA 2023), held in conjunction with
ICAIL 2023, June 19, 2023, Braga, Portugal.
* Corresponding author: dan.hunter@kcl.ac.uk
                                © 2023 Copyright for this paper by its authors. Use permitted under Creative
                                Commons License Attribution 4.0 International (CC BY 4.0).

                                CEUR Workshop Proceedings (CEUR-WS.org)
    CEUR
                 ht
                  t /
                   p:c
                     /e -
                       ur .
                         wsog
                            r
    Workshop     SSN1613-
                 I      0073
     o
    Prceedings
“completion”) [12]. Text embeddings measure the        engine for several tools that generate legal and
relatedness of text strings and can be employed to     regulatory content in multiple forms. The
enhance LLMs’ contextual understanding for             platform can accurately and reliably horizon scan
more accurate outputs. This technique allows           various public sources of information to generate
LLMs to effectively perform tasks like custom          regulatory newsfeeds, as well as generate
search     applications,     summarisation,     and    obligations registers from legislation, regulations,
classification, where the context may be largely       and policy. It can also automatically create expert
contained in the prompt. Thus, clever prompt           system-like consultation tools directly from legal
engineering can generate valuable outputs without      text.
the need for any fine-tuning or (worse) retraining
of the model. The first reported job advertisement         Originally the team behind Gracenote worked
for a legal prompt engineer was posted by the UK       with trained lawyers to create regulatory updates,
law firm Mishcon de Reya, [13] but the skill is one    obligations registers, and rule-based consult tools.
that numerous law firms and companies now need         But now it uses LLM prompt engineering
[14].                                                  techniques to automatically generate the content
                                                       from public sources such as press releases,
   The combination of simplicity in prompt             regulatory alerts, case reports, and legislation.
engineering and ease of access to foundation           Lawyers in our law firm clients view the
models has led to a proliferation of generative AI     generated completions side-by-side with the
companies and products in law. The highest             original content, in order to assess accuracy,
profile example of this is the generative AI           validity and relevance prior to publication
company Harvey.ai, which seeks to redefine elite       internally to practice groups or externally to
legal and consultancy practice by using OpenAI’s       clients. The current platform has been trialled in a
LLMs as the foundation engine [15]. But other          range of sectors including financial services,
legal examples include companies focused on            insurance, and cybersecurity.
generative AI legal drafting solutions [16] or
contract lifecycle maintenance [17].                      In this paper, we report on our research into the
                                                       use of generative AI to solve GRC issues and
   Our company, Gracenote, adopts the same             document the methods and tools we use to solve
methodology of building legal products on top of       three different GRC problems using LLMs. These
LLMs as the core engine, using a combination of        three problems are the creation of regulatory
prompt engineering, text embeddings, model fine-       newsfeeds from public sources, the generation of
tuning, and NLP-based techniques. We use a             obligations from legislative material, and the
range of foundation models to create legal tools       creation of consultation tools from legislation.
that solve commercial regulatory and compliance
issues. Governance, risk and compliance                    The research advances reported on in this
(generically referred to as “GRC”) is the business     paper will focus on (1) legal prompt engineering
function where laws and regulations intersect          techniques to generate GRC solutions from multi-
most directly with business and commerce. It is a      modal legal source documents (e.g. regulatory
useful arena to test the ability of generative AI to   press     releases,    legislation,   explanatory
undertake legal tasks, for a range of reasons.         memoranda, and legal cases); (2) the difference in
Notably, the scale of the problems in GRC are          accuracy and quality of content generated by
vast, the people using these platforms usually are     different LLMs; and (3) design considerations
not lawyers, they typically need lots of guidance,     that reduce the hygiene problems inherent in using
and the implications of getting the answers wrong      generative AI models in legal settings—including
are very serious. GRC tools built using                the hallucination problem, privacy issues in
appropriately configured/constrained LLMs and          passing     personally-identifying    data,    and
using various generative AI methods can address        confidentiality issues in passing commercially-
many of these issues.                                  sensitive data.

    Gracenote works with law firms and                    The paper proceeds as follows. In Section 2 we
consultancies    to   create  generative    AI         document our methods in using generative AI to
environments to solve the GRC problems of their        perform horizon scanning of regulatory material
clients using our tools. We have developed a           and generate regulatory newsfeeds. In Section 3
platform that uses OpenAI’s GPT-4 model as the         we discuss methods of creating obligations
registers from legislative material, and in Section    supported websites, ensuring the database stays
4 we sketch a solution to the automatic creation       up to date with the latest information. The
and maintenance of legal expert systems using a        periodicity can be adjusted for each regulatory
combination of generative AI techniques. In            feed depending on the speed and velocity of
Section 5 we discuss methods for reducing the          content publication. Generally, most sites are
well-documented generative AI issues of                monitored hourly, but it is possible to monitor
hallucination and privacy/confidentiality leakage.     more regularly.
In Section 6 we provide conclusions and note the
further work that we have begun undertaking to             In the pilot phase, we support scraping from
improve our tools and methods.                         Australian regulatory bodies including the
                                                       Australian      Securities     and     Investments
2. Generative          AI    for     regulatory        Commission, the Australian Transaction Reports
                                                       and Analysis Centre, the Australian Prudential
   newsfeeds                                           Regulation Authority, the Office of the Australian
                                                       Information      Commissioner       (OAIC),      the
   Law firms and the risk/compliance officers of       Australian Financial Complaints Authority, the
corporations need to be apprised of upcoming           Reserve Bank of Australia, and the Australian
changes in various laws. The traditional way of        Taxation Office (ATO). While most pages can be
performing this function is to use a horizon           scraped by simply obtaining the initial response,
scanning service like Lexology [18] that uses          some websites such as the OAIC and the ATO
human editors to find and summarise upcoming           require the use of a headless browser to enable
regulatory change.                                     JavaScript execution. This is necessary as the list
                                                       of media releases is served through JavaScript.
   Gracenote uses automatic horizon scanning           Apart from this distinction, the general HTML
and scraping methods to find and access                structure of the supported pages is largely
regulatory information, and then uses generative       identical. Additionally, user-specified links can be
AI methods to summarise and categorise the             processed, albeit without the post-processing
information for clients.                               function that sanitises and categorises the page
                                                       content.
2.1.    Horizon scanning
                                                          As an extension of this research, our future
                                                       work will investigate the capabilities of advanced
    For regulatory update horizon scanning, the
                                                       frameworks, such as AutoGPT [19] and
platform automatically monitors feeds that are
                                                       LangChain [20], in creating AI agents that
identified by a law firm practice group and scrapes
                                                       autonomously navigate the web and execute
all new information coming from that feed. It
                                                       searches. The objective of these agents is to
sends a notification to the responsible author in
                                                       extract information from a broad range of industry
that group alerting them to the new content and
                                                       news sites and media outlets, which is particularly
summary.
                                                       useful in the context of rapidly evolving or
                                                       emerging regulatory change. By leveraging this
    The scraping process can be decomposed into
                                                       approach, law and consulting firms can
a few parts. First, to streamline the scraping
                                                       proactively respond to breaking news without
process, the update tool uses an abstract class
                                                       solely relying on updates from regulatory
containing generic methods and variables, e.g.
                                                       authorities’ official channels.
relevant data fields, methods to insert entries into
the database, etc. The abstract class is
implemented in classes specific to each website,       2.2.    Prompt      engineering                for
utilising unique regular expression patterns and/or            regulatory newsfeeds
a document object model crawler. This approach
enables the efficient location of media release
                                                           The scraped material from the update is
links, titles, and publication dates on their          inserted into a SQL database, and then a series of
respective news pages.                                 GPT prompts are generated using the scraped
                                                       content as part of the prompt context. These
   Using a cronjob, the system periodically            prompts are used to generate three discrete types
checks for new regulatory material on the
                                                       of completions that are then stored in the database:
   1. An arbitrarily long summary of the              Long Form Text: Case Law and Consultation
      scraped content (default is 150 tokens).        Papers
   2. An impact level, labelled as “high”,               GPT is constrained by token limits. The
      “medium” or “low” impact, which aids in         version of GPT-4 that we use can only process
      the organisation and presentation of the        approximately 3,000 words at a time, meaning we
      generated updates.                              need a different solution for long form text. While
   3. Hashtags that specify the type of content       more advanced versions of GPT-4 can process
      scraped and the main topic(s) that the          25,000 words at a time, we will still need a
      content covers.                                 chunking solution for longer form text such as
                                                      certain case law and consultation papers. Over
   These three methods are discussed in more          time, we anticipate that future versions of GPT
detail below.                                         with higher context windows may make this
                                                      chunking solution obsolete for this particular use
 2.2.1. Summarisation methods                         case, though we expect to find future applications
                                                      for it.
   We use mixed methods for the first
                                                         The chunking solution works as follows:
completion, depending on the content type which
is scraped. These content types fall into three             1. Divide the original text into an array of
categories: general media releases, long form text,
                                                               sections, each under the model’s token
and adjudications.                                             limit.
                                                            2. Create an array of summaries for each
General Media Releases                                         section.
  For creating general summaries using GPT-4,               3. Continue summarising array entries by
we use a version of the following prompt:
                                                               concatenating them together under the
   Summarise the key regulatory updates
                                                               token limit until the total number of
from the media release below, keeping                          characters in the array is under the
within a 125-word limit. Use Australian                        token limit.
English spelling. To ensure conciseness,                    4. Concatenate the array and return the
use commonly accepted abbreviations or
acronyms for Australian regulatory bodies
                                                               final summary.
or courts, such as “ASIC” for the
Australian Securities and Investments                    For future work, we propose to incorporate a
Commission or “FCA” for the Federal Court             system message at the beginning explaining what
of Australia. Ensure the summary is
professional, factual, and authoritative,
                                                      the task is (i.e., “summarise the following
without any embellishments or rhetoric.               future messages”) to improve token efficiency.
Begin with “On [insert date], “. Relevant             We further propose to integrate LangChain
text: [Source material]                               document loaders and text splitters to chunk the
                                                      original text based on the structure of the source
    Older OpenAI models (Davinci-003) would           material. That is, instead of using an arbitrary end
struggle with special characters. However, GPT-       point, each chunk will be created based on rich
3.5 and GPT-4 do not face this issue. This allows     information such as sections, headings and page
us to scrape the raw text data contained within the   numbers.
relevant scraped source material and produce a
summary, enabling a more standardised approach        Adjudication Summary
to scraping that will be compatible with future AI       Summarising case law is a more complex
agents. It further allows us to preserve rich         prompt engineering exercise. At present we only
information, such as headings, lists and              summarise decisions from the Australian
paragraphs, all of which can assist in the final      Financial Complaints Authority (AFCA). These
presentation of the completion.                       decisions are relatively well-structured and
                                                      templated, compared with other higher-level
                                                      appellate court decisions. Even so, the prompt
                                                      engineering is quite complex.
    We use multiple prompts to create tailored     generation of distinctive summaries that can serve
completions of adjudication summaries, as          as foundational material across multiple of law
follows:                                           and consulting firms.

   Create a title which first states the
shortened names of the parties involved             2.2.2. Categorisation methods
in the format of “X v Y”, before including
a colon symbol and a very short summary               We use prompt engineering to categorise
of the complaint. Use Australian English
spelling.   Write   in   a   concise   and         regulatory newsfeeds, both for impact and for
authoritative    tone.    Relevant   text:         document/topic type classifications, as follows.
[insert pages 1 & 2]
                                                   Impact Level Assignment
   Summarise    the   background   of   the            For categorising impact levels, we use the
complaint to AFCA in less than 125 words.
Include a description of the parties               following prompt:
involved and their roles. Do not state
the role of AFCA or the outcome of the                Your task is to categorise regulatory
complaint.     Use    Australian    English        updates into ‘high’, ‘medium’, and ‘low’
spelling.    Write   in   a   concise   and        impact   levels.   Simply   respond   with
authoritative     tone.   Relevant    text:        ‘high’,   ‘medium’,   or   ‘low’   without
[insert pages 1 & 2]                               additional words or explanations. Here is
                                                   a summary of each impact level category.
   Summarise the issues, key findings,             High impact may only be used when a new
reasons for the determination, and basis           law or regulation comes into effect.
for why the outcome is fair (citing                Medium impact refers to criminal or civil
specific facts) into medium-sized bullet           charges filed against an individual or
point sentences. Retain the original               organisation,    sentencing,    regulatory
heading structure used in the issues and           enforcement    actions,   class    orders,
key findings section. Use Australian               registering new instruments, consultation
English spelling. Write in a concise and           papers, and other similar developments.
authoritative   tone.   Relevant   text:           Low impact refers to legislative sitting
[insert pages 1 & 2]                               dates, general industry news, and other
                                                   updates. Most regulatory updates are low
   Summarise     the    outcome    of   the        and medium impact. Relevant text: [Source
determination made by AFCA in less than            material]
75   words.     Use   Australian    English
spelling.    Write   in    a  concise   and           This prompt allows us to determine how
authoritative     tone.    Relevant   text:
[insert 1.3 Determination]                         impactful a regulatory update is, which assists in
                                                   prioritising content consumption of the regulatory
   Create   a  3-bullet    point  summary          newsfeeds.
extracting essential information about
the   complaint.   Specify   the  parties
involved (ignoring AFCA), the reason for           Topics and Document Type
the complaint, and the outcome of the                  To categorise document type, we use the
determination by AFCA (including why the           following prompt:
determination was fair). Use Australian
English spelling. Write in a concise and              Your task is to analyse the source
authoritative    tone.   Relevant   text:          material provided and categorise it by
[insert outputs of above prompts]                  assigning the most appropriate document
                                                   type hashtag. Choose only one hashtag
   This approach allows us to create a summary     from the options below. Do not create new
that can be directly inserted into a regulatory    hashtags. Document type hashtags: #Media
                                                   #Consultation #Enforcement #Legislation
newsfeed by simply scraping a PDF of the AFCA      #Adjudication. [Source material]
decision.
                                                      For categorising topic, we use the following
    In each of the aforementioned summary          prompt:
prompts, we employed a higher temperature
setting, ranging between 0.5 and 0.7. This            Your task is to analyse the source
elevated temperature allows the LLM to consider    material provided and categorise it by
words with marginally lower probabilities, thus    assigning the most appropriate topic
                                                   hashtag. Choose only one hashtag from the
introducing increased variation, randomness, and   options   below.   Do  not   create   new
creativity. Consequently, this facilitates the     hashtags. Topic hashtags: #Accountability
#Audit #AFCA #AML #APRA #ASIC #Climate                  to keep up with regulatory change, raising legal
#ConsumerProtection    #Credit    #Crypto
                                                        and reputational risk [21]. Our collaborative
#Digital   #Employers    #FinancialAdvice
#FundMergers   #Insurance    #Investments               findings with partner law firms and consultancies
#Licensing #Parliament #Payments #Privacy               estimate that the integration of our regulatory
#PrudentialStandards          #Regulators               newsfeeds solution can save approximately one
#Retirement #SMSF #Tax #Transparency.
[Source material]
                                                        FTE in small to medium-sized corporate legal
                                                        teams. We expect this resource optimisation to
    The above prompts allow us to further               free up internal capacity and enable teams to
categorise regulatory updates to support the            concentrate more on value-added delivery.
navigation of our regulatory newsfeeds, allowing
clients to select the topics they are interested in     3. Obligations from legislation
and receive tailored alerts. They can also combine
topics and document types to extract insights,              An important part of any compliance function
such as all the enforcement actions which ASIC          is a canonical list of obligations that apply to the
commenced in the last six months against crypto-        business. The register is canonical in the sense
related products. We can see this being a valuable      that it provides a definitive, authoritative and
research tool for regulatory change management.         universally accepted list of obligations which
                                                        apply to the business. Many corporate legal teams
2.3.    User interface                                  rely on external providers to prepare an initial
                                                        obligations register. However, as regulatory
   There are two different interfaces, one for an       change is fast-moving, these registers typically
author/publisher and one for the end-user/client.       become outdated quickly. Alternatively, legal
                                                        teams may subscribe to an obligations register
    For the authoring tool, upon login the author is    service, which typically cost between
presented with all work product that is pending         AU$50,000-$100,000 per year. However, even
from monitored feeds for that author. The author        these solutions often fail to keep up with the
can adjust which feeds are monitored from a             commencement date of new obligations, as their
settings page.                                          registers are human created and inefficient.

    The authoring environment itself has three             We use a range of generative AI solutions to
main panes—the leftmost pane (“ASIC places              create a register of obligations from various types
interim stop orders...”) is the timeline for all        of legislative and regulatory material. This
content still to be published, the middle pane is the   solution is fast, cost-effective and—where
original content from the monitored source, and         appropriately monitored—canonical.
the rightmost pane contains the GPT-generated
content. The author compares the original source            The general approach is standard across all
with the summary to assess accuracy and quality,        LLM types and allows users to paste a URL to a
and they can adjust settings on the prompt and edit     table of contents page, generating an obligations
the summary prior to publication. This is done to       register. The system systematically opens each
reduce the hallucination/integrity issues inherent      link to every provision of the act and extracts text
in LLMs. (A topic which we examine in more              to summarise detected obligations.
detail in section 5 below.). Refer to Figure 1 in
Annexure A.                                                 During the development process of this tool,
                                                        we moved from GPT-3.5 to GPT-4, and the nature
                                                        of the prompts changed in interesting ways.
   Upon publishing the content, the update is
stored in a structured form and can be used in
external law firm workflows—e.g., bulk email               The GPT-3.5 prompt used was:
systems, newsletters, etc—or pushed to the client          Obligations generally say a person
using our client interface as shown in Figure 2 of      'must'   do   something.   Summarise  the
Annexure A.                                             obligation in the following text in as
                                                        few words as possible. An acceptable
                                                        degree   of   legal   accuracy   must  be
   Regulatory change management in Australia            maintained. Do not use list or bullet
presents a considerable challenge to corporate          point formatting. Where a list of
legal teams. 72% of these teams report struggling       exceptions applies to the obligation,
simply state the relevant subsection                 GPT-4 produced obligations exhibiting greater
rather than outlining every exception.
                                                     legal precision compared to our human-generated
Begin by saying 'a [insert] must'. Do not
state the nature of the offence. If no               reference registers. For instance, the obligation
obligation   is   detected,   state   ‘No            listed in our reference register for Section 912DA
obligation detected’. Use Australian                 of the Corporations Act simply stated, “A licensee
English spelling. Relevant text: [source
material]
                                                     must notify ASIC of changes in control.” In
                                                     contrast, the GPT-4-generated obligation
   A key issue with GPT-3.5 is its tendency to       provided a more legally accurate description: “A
add embellishments or write more text than           financial services licensee must notify ASIC of
necessary. Despite instructions to avoid stating     changes in control within 30 business days, using
the nature of the offence, GPT-3.5 regularly did     the prescribed form.” The key distinction between
so. Several attempts to tune the prompt were         the two is the specific time limit, which the human
unsuccessful.                                        missed.

  We were more successful with GPT-4. The               All completions/obligations are stored in a
GPT-4 prompt used was:                               local database, which is then post-processed for
                                                     duplicates and other issues. That is, after
   Obligations generally say a person                assembling a register from multiple sources of
'must'   do   something.    Summarise  the           law, it’s necessary to merge functionally
obligation in the following text in a                equivalent obligations. For example, the high-
manner   that    is   sufficient   for  an
obligations register. Write concisely but
                                                     level obligation to “… not engage in misleading
maintain an acceptable degree of legal               or deceptive conduct” is covered by various
accuracy. Do not use list or bullet point            sources of law depending on the context but
formatting. Where a list of exceptions               should be merged into one obligation for the
applies to the obligation, simply state
the relevant subsection rather than
                                                     purposes of an obligations register.
outlining every exception. Begin by
saying 'a [insert] must'. Do not state                  To check for matching or functionally
the nature of the offence. If no                     equivalent obligations in a spreadsheet, we
obligation    is    detected,   state  ‘No           perform the following operations:
obligation detected’. Use Australian
English spelling. Relevant text: [source
material]                                                  1. Import the obligations register into the
                                                              Python environment, using the pandas
   GPT-4 naturally writes more concisely than                 library.
GPT-3.5. Therefore, we found that a prompt                 2. Clean and normalise the text data by
containing words to the effect of “in as few words            converting it to lowercase, removing
as possible” was interpreted too literally. We                punctuation, stop words, and stemming
tuned the prompt to balance writing concisely                 or lemmatizing the words. We use the
with maintaining a degree of legal accuracy                   nltk or spaCy libraries for this purpose.
acceptable for creating an obligations register.           3. Convert the text into numerical
GPT-4 “understood” the task better than GPT-3.5               representations and using TF-IDF
and can reliably produce outputs that do not                  (Term frequency – Inverse document
include the nature of the offence.                            frequency) to compare the similarity
                                                              between      the    obligations     more
    To ensure legal accuracy in the generation of             effectively.
obligations, we employed a lower temperature               4. Use cosine similarity to compare the
setting, ranging between 0.0 and 0.3. This lower              numerical representations of each pair
temperature restricts the LLMs output to the most             of obligations, to generate a similarity
probable words, reducing variation and                        score to identify matching/functionally
encouraging     more      precise,   deterministic            equivalent obligations, which is then
completions. This heightened level of                         assessed against a pre-defined score of
predictability and accuracy is crucial in the                 “matching”        or       “functionally
context of generating obligations registers.                  equivalent.”
                                                           5. Flag those obligations that have a score
   We evaluated the system using diverse                      above the chosen threshold, and have a
legislative documents, and in certain instances,              user validate that these obligations are
          in-fact matching       or   functionally    vectorized user query to generate a list of
          equivalent.                                 similarities, which are then passed to GPT-4,
                                                      along with a system message, to produce a
   In validation and testing, we found similarity     completion.
detection to be accurate in most cases. However,
in some instances, the system identified                  The full description of this process is as
obligations that sounded similar but were not         follows:
functionally equivalent.
                                                           1. Prepare an obligations register and
   Some examples of the algorithm’s matched                   export it to a CSV file (columns include
obligations include the requirement under                     ‘legislation’, ‘section number’, and
Australian laws for financial services licensees              ‘obligation description’)
not to engage in unconscionable conduct under              2. Initialise the dataset using LangChain
Section 991A of the Corporations Act 2001 (Cth)               CSVLoader. [23]
(Corporations Act), and the requirement for a              3. Split the dataset into chunked text data
                                                              using LangChain        Character    Text
person not to engage in unconscionable conduct
                                                              Splitter. [24]
under Section 12CA of the Australian Securities
                                                           4. Send the chunked text data to Open
and Investments Commission Act 2001 (Cth)                     AI’s Embeddings API (model: text-
(ASIC Act). Another example is the obligation                 embedding-ada-002). Open AI returns
not to participate in misleading and deceptive                text as vectors. [22]
conduct under Section 1041H of the Corporations            5. Use LangChain ChatGPT Plugin
Act and Section 12DA of the ASIC Act.                         Retriever to combine the text as vectors
                                                              with a vectorized user query (i.e.,
   We are conducting further research on large                 “List all the obligations I may
semantic search operations to improve the quality              have breached by [insert]”) and a
of similarity check outputs, but even with the                 system message (i.e., “Use the
                                                               following pieces of legal text
current process, we can very quickly assess and                to answer the question at the end
accept       or    reject      obligations     as              [insert]” ) to prompt Open AI’s
matching/equivalent. This process, in addition to             ChatGPT (model: gpt-4) for reasoning.
the generative AI creation of the obligations,                [25]
significantly speeds up register generation and            6. Open AI returns the final output.
maintenance.
                                                      Two examples of the interaction with this tool
4. LLM-based expert systems                           give an idea of how the system works:

    Related to the automatic generation of            Scenario 1
obligations registers, we have developed a method        User prompt
                                                        Failing to keep records of income
to use GPT-4 as an engine for an expert system
consultation tool. This is similar in some ways to      Response
a traditional legal expert system—the topic of           Life Insurance Act 1995, Section 75: A
many ICAIL papers thirty years ago—but the            life company must keep records of income
system is constructed in a distinctive way, and the   and outgoings for each statutory fund.
interface operates differently.                          Life Insurance Act 1995, Section 76: A
                                                      life company must keep records of income
    Our approach leverages the method of              and   outgoings   for   overseas   funds.
generating obligations registers described in
                                                         Corporations Act 2001, Section 988B:
section 3 above. The obligations register is          The records must be kept in a way that
processed using the LangChain framework [20]          enables true and fair profit and loss
and OpenAI’s word embeddings tool [22] to             statements, and balance sheets, of the
vectorize the register. LangChain is a framework      financial   services  business   of   the
                                                      licensee to be prepared from time to time
for developing advanced applications powered by       and allows those statements and balance
LLMs. Our application uses LangChain to               sheets to be conveniently and properly
compare the vectorized obligations register with a    audited.
                                                      creating text that sounds plausible but is utterly
Scenario 2                                            wrong. This poses a huge risk for unsupervised
   User prompt                                        generative AI systems within a law firm, where
   Giving misleading information to an                accurate advice is a fundamental requirement of
auditor
                                                      legal practice.
   Response
   Corporations Act 2001, Section 1309: A                 The Gracenote platform controls for the
company   must    not   give   misleading             hallucination problem by requiring all content to
information about a company to a director             be approved by a responsible person within the
or auditor knowing its misleading. A
                                                      firm, typically a partner. Content is never
company must take reasonable steps to
ensure it does not give misleading                    published by the generative AI model; instead, the
information about a company to a director             model generates draft content according to
or                               auditor.             agreed-upon prompts and displays this side-by-
                                                      side with the material from the feed. The human
   Financial Sector (Collection of Data)
Act 2001, Section 17D: Giving knowingly               author assesses the correctness of the content, can
false information to an auditor of a                  edit it as necessary, and only then publishes the
reporting entity or failing to take                   content to the database—which is then used to
reasonable steps to avoid doing so.
                                                      send content externally to practice groups or
   Life Insurance Act 1995, Section 91(1):            client.
An employee or officer of a life company
must not give false or misleading                        This type of control—often called “human-in-
information to an auditor regarding the               the-loop”—ensures that a law firm is never
affairs       of        the       company.
                                                      exposed to risk of poor-quality content going out
   Life Insurance Act 1995, Section 91(2):            under its name. This type of control also mitigates
An employee or officer of a life company              issues with semi-random changes in completions
must take reasonable steps not to give                that can occur with some models. In essence,
false or misleading information to an
auditor regarding the affairs of the                  because a responsible human will always control
company.                                              the editing and dissemination of content, it
                                                      doesn’t matter that a prompt to any given LLM
    In each of the above scenarios, lawyers           may generate slightly different completions over
reviewed the outputs provided by GPT-4 and            time.
confirmed that they were relevant and accurate
based on the information supplied in the user             Privacy and confidentiality are two other
prompt. These results demonstrate the potential of    hygiene concerns with the use of LLMs in legal
this tool to streamline the obligations assessment    settings.   Sending      personally    identifying
process for corporate legal teams and licensees.      information to a public endpoint of a LLM may be
To address confidentiality concerns, the intended     a breach of various privacy laws, including the
interactions with this tool is used in hypothetical   GDPR or the Australian Privacy Act 1998 (Cth).
scenarios only.                                       Similarly, using confidential information as a
                                                      prompt for a LLM may lead to disclosure of that
   Significant testing of the validity of this        information, contrary to a range of ethical/legal
approach is necessary for deployment in               professional practice laws, as well as the
commercial settings; but initial user feedback has    commercial interests of a firm.
demonstrated the basic utility of the approach.
                                                          To address these concerns, we propose two
5. Mitigating    problems                   with      strategies. For scenarios involving sensitive user
                                                      information, we propose the use of privately-
   generative AI                                      hosted open-source models or privately-hosted
                                                      proprietary models. This approach provides a
   One of the features of generative AI models is     layer of security, ensuring that confidential
that they have no internal representation of the      information remains within a secure, controlled
world, and instead they are merely generating text    environment within a set jurisdiction. On the other
one word at a time, based on a mathematical           hand, when working with publicly available
analysis of what word should follow from the          information, we expect to continue utilising
previous ones. This means that they are prone to      public proprietary models such as GPT-4. The
rationale behind this strategy lies in the superior             register from multiple sources of law,
reasoning capabilities these models are expected                including specific divisions from those
to maintain. Their performance is attributable to               sources. The register can then be deployed
the substantial compute and vast datasets involved              via an API connection to various
in their training process, an advantage open-                   governance, risk, and compliance
source models might lack. We do not use private                 platforms. Finally, this tool will have a
or confidential information in any of the tools                 method for versioning legislative
described here, and so we haven’t needed to use                 provisions. This feature will enable users
privately-hosted open-source models or privately-               to import amending legislation, which will
hosted proprietary models.                                      update the relevant provisions of the
                                                                primary register. A GitHub-style approach
6. Conclusions and further work                                 will be used to commit changes to
                                                                production registers, allowing for an
                                                                affordable and always up-to-date
   To the best of our knowledge there is no other
                                                                obligations register.
generative AI company that focuses on GRC
problems in the way we do. We believe that the              3. For the expert system generator, we plan
tools and methods described here are advances on
                                                               to investigate the inclusion of penalties in
the state of the art in the delivery of legal services         the dataset to enable GPT-4 to reason
and compliance functions using generative AI.                  whether an obligation is “deemed
                                                               significant” and determine if a breach of
   Our future work includes the following:                     those obligations is reportable to
                                                               regulators. We also propose to extend the
   1. For the horizon scanning tool, we are                    approach to a range of other pieces of
      working with a range of law firm clients to              legislation, in multiple jurisdictions. We
      expand the range of supported feeds, in
                                                               believe that this approach has significant
      multiple jurisdictions and languages                     benefits over other methods of producing
      (Australia, England and Wales, Singapore,
                                                               expert system tools and is an advance on
      and the USA). We are working on being                    the standard methods. We also believe that
      able to tailor the tone of the summary from              it can provide a more comprehensive and
      formal to informal to support a wider                    accurate solution to streamline the
      range of audiences and clients. We are also              assessment and reporting of compliance
      working on improving link sanitisation for
                                                               breaches.
      the one-off insertion of links by users, and
      refining prompts to improve the quality of            Generative AI models will change a huge
      outputs for various subject matter. As an          range of legal functions, and one of these is in
      extension of this research, we will                legal and regulatory compliance. LLMs provide
      investigate creating AI agents that                remarkable opportunities to improve decision-
      autonomously navigate the web and                  making in law, as we have demonstrated with the
      execute searches, enabling law and                 tools and methods, we have developed within
      consulting firms to proactively respond to         Gracenote.
      rapidly evolving or emerging regulatory
      updates from a broad range of industry
      news sites and media outlets.                      7. References

   2. For the obligations-generation tool, we are        [1] Rupert Macey-Dare, “How ChatGPT and
      working on a user-friendly interface to                Generative AI Systems will Revolutionize
      facilitate the management of obligations               Legal Services and the Legal Profession.
      and provide a seamless experience for                  Retrieved      May      5,    2023     from
      users. We are also working on supporting               https://papers.ssrn.com/sol3/papers.cfm?abs
      multiple jurisdictions, languages and tones            tract_id=4366749
      for different audiences. We also propose           [2] Daniel Martin Katz, Dirk Hartung, Lauritz
      developing an interface for building                   Gerlach, Abhik Jana and Michael J.
      registers from various sources of law. This            Bommarito, Natural Language Processing in
      interface will enable users to construct a             the               Legal             Domain.
     https://papers.ssrn.com/sol3/papers.cfm?abs          experience.            (April          2023).
     tract_id=4336224                                     https://www.resumebuilder.com/9-in-10-
[3] Daniel Schwarcz & Jonathan H. Choi, AI                companies-that-are-currently-hiring-want-
     Tools for Lawyers: A Practical Guide.                workers-with-chatgpt-experience
     https://papers.ssrn.com/sol3/papers.cfm?abs     [15] Gabriel Pereyra and Winston Weinberg.
     tract_id=4404017                                     Sequoia and OpenAI Back Harvey to
[4] Daniel Martin Katz, Michael James                     Redefine Professional Services, Starting with
     Bommarito, Shang Gao and Pablo                       Legal.       Harvey.ai.     (April     2023).
     Arredondo, GPT-4 Passes the Bar Exam.                https://www.harvey.ai/blog
     https://papers.ssrn.com/sol3/papers.cfm?abs     [16] CaseText. Meet CoCounsel-the world’s first
     tract_id=4389233                                     AI legal assistant. (March 2023).
[5] OpenAI. 2023. GPT-4 Technical Report.                 https://casetext.com/blog/casetext-
     DOI: https://arxiv.org/abs/2303.08774                announces-cocounsel-ai-legal-assistant
[6] Stuart Hargreaves, ‘Words Are Flowing Out        [17] RobinAI. Unleash the Power of Large
     Like Endless Rain Into a Paper Cup’:                 Language Models in the Legal Industry with
     ChatGPT & Law School Assessments.                    Robin         AI.       (February      2023).
     https://papers.ssrn.com/sol3/papers.cfm?abs          https://www.robinai.co.uk/post/large-
     tract_id=4359407                                     language-models-legal-industry
[7] Ilias Chalkidis, ChatGPT May Pass the Bar        [18] Lexology.               (May            2023.
     Exam Soon, but as a Long Way to Go for the           https://www.lexology.com/
     LexGLUE                          Benchmark.     [19] AutoGPT.               (May            2023).
     https://arxiv.org/abs/2304.12202                     https://github.com/Significant-
[8] Jonathan H. Choi, Kristin E. Hickman, Amy             Gravitas/Auto-GPT
     B. Monahan and Daniel Schwarcz, ChatGPT         [20] LangChain.              (May           2023).
     Goes           to        Law          School.        https://langchain.com
     https://papers.ssrn.com/sol3/papers.cfm?abs     [21] Hannah Wootton, In-house lawyers ‘failing
     tract_id=4335905                                     to manage regulatory, business risks’. (29
[9] Kwan Yuen Iu & Vanessa Man-Yi Wong,                   April 2021) Retrieved May 5, 2023 from
     ChatGPT by OpenAI: The End of Litigation             https://www.afr.com/companies/professiona
     Lawyers?                                             l-services/in-house-lawyers-failing-to-
     https://papers.ssrn.com/sol3/papers.cfm?abs          manage-regulatory-business-risks-
     tract_id=4339839                                     20210428-p57n79
[10] Tyna Eloundou, Sam Manning, Pamela              [22] Ryan Greene, Ted Sanders, Lilian Weng, and
     Mishkin, and Daniel Rock. 2023. GPTs are             Arvind Neelakantan. 2022. New and
     GPTs: An Early Look at the Labor Market              improved embedding model. OpenAI.
     Impact Potential of Large Language Models.           (December                              2022).
     DOI:                                                 https://openai.com/blog/new-and-improved-
     https://doi.org/10.48550/arXiv.2303.10130            embedding-model
[11] OpenAI.                          Fine-tuning.   [23] Harrison Chase. CSV Files. LangChain.
     https://platform.openai.com/docs/guides/fin          (May                                   2023).
     e-tuning                                             https://python.langchain.com/en/latest/modu
[12] OpenAI. (February 2023). Model index for             les/indexes/document_loaders/examples/csv
     researchers.                        OpenAI:          .html
     https://platform.openai.com/docs/model-         [24] Harrison Chase. Character Text Splitter.
     index-for-researchers                                LangChain.              (May           2023).
[13] LawCareers.Net, Law firm to hire ‘AI                 https://python.langchain.com/en/latest/modu
     engineer’ to identify how its lawyers can use        les/indexes/text_splitters/examples/character
     ChatGPT. (March 2023) Retrieved May 5,               _text_splitter.html
     2023                                    from    [25] Harrison Chase. ChatGPT Plugin Retriever.
     https://www.lawcareers.net/Explore/News/L            LangChain.              (May           2023).
     aw-firm-to-hire-AI-engineer-to-identify-             https://python.langchain.com/en/latest/modu
     how-its-lawyers-can-use-ChatGPT-060320               les/indexes/retrievers/examples/chatgpt-
[14] ResumeBuilder. 9 in 10 companies that are            plugin-retriever.html
     currently hiring want workers with ChatGPT
Annexure A – User interface




                          Figure 1: Authoring environment




                              Figure 2: Client environment
