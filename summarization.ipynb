{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRYSu48huSUW",
        "outputId": "02733255-d061-4563-c8cf-f4212fc70715"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
          ]
        }
      ],
      "source": [
        "!pip -q install langchain openai==0.27.0 tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wW6FD6FsT5Qf"
      },
      "source": [
        "# Summarization\n",
        "\n",
        "History  \n",
        "Challenges  \n",
        "Fine-tuning  \n",
        "Instruct Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "dNA4TsHpu6OM"
      },
      "outputs": [],
      "source": [
        "from secret_key import openapi_key\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = openapi_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-KFB7J_u_3L",
        "outputId": "5657944a-c8fe-48dd-d131-9a649d84b785"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: langchain\n",
            "Version: 0.0.184\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: https://www.github.com/hwchase17/langchain\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: C:\\Users\\User\\anaconda3\\envs\\new\\Lib\\site-packages\n",
            "Requires: aiohttp, dataclasses-json, numexpr, numpy, openapi-schema-pydantic, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "!pip show langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqwsGJDhvAQ5"
      },
      "source": [
        "### Setting up Summarization Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "lgesD0jrvDyG"
      },
      "outputs": [],
      "source": [
        "from langchain import OpenAI, PromptTemplate, LLMChain\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.chains.mapreduce import MapReduceChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "llm = OpenAI(temperature=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "pyPulL7tvQOw"
      },
      "outputs": [],
      "source": [
        "text_splitter = CharacterTextSplitter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Created a chunk of size 601, which is longer than the specified 170\n",
            "Created a chunk of size 2064, which is longer than the specified 170\n",
            "Created a chunk of size 1698, which is longer than the specified 170\n",
            "Created a chunk of size 4963, which is longer than the specified 170\n",
            "Created a chunk of size 2992, which is longer than the specified 170\n",
            "Created a chunk of size 1462, which is longer than the specified 170\n",
            "Created a chunk of size 3135, which is longer than the specified 170\n",
            "Created a chunk of size 4666, which is longer than the specified 170\n",
            "Created a chunk of size 3084, which is longer than the specified 170\n"
          ]
        }
      ],
      "source": [
        "# load the doc\n",
        "with open('paper3.txt') as f:\n",
        "    how_to_win_friends = f.read()\n",
        "\n",
        "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=170, chunk_overlap=0\n",
        ")\n",
        "texts = text_splitter.split_text(how_to_win_friends)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Abstract: We investigate the transformative potential of large language models\\n                                (LLMs) in the legal and regulatory compliance domain by developing advanced\\n                                generative AI solutions, including a horizon scanning tool, an obligations generation\\n                                tool, and an LLM-based expert system. Our approach combines the LangChain\\n                                framework, OpenAI’s GPT-4, text embeddings, and prompt engineering techniques\\n                                to effectively reduce hallucinations and generate reliable and accurate domain-\\n                                specific outputs. A human-in-the-loop control mechanism is used as a final backstop\\n                                to ensure accuracy and mitigate risk. Our findings emphasise the role of LLMs as\\n                                foundation engines in specialist tools and lay the groundwork for building the next\\n                                generation of legal and compliance applications. Future research will focus on\\n                                extending support across multiple jurisdictions and languages, refining prompts and\\n                                text embedding datasets for enhanced legal reasoning capabilities, and developing\\n                                autonomous AI agents and robust LLM-based expert systems.'"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texts[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "sCfCSX9sOv2A"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.docstore.document import Document\n",
        "\n",
        "docs = [Document(page_content=t) for t in texts[:4]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='Gracenote.ai: Legal Generative AI for Regulatory Compliance\\nJules Ioannidis, Joshua Harper, Ming Sheng Quah 1 and Dan Hunter 1, 2\\n1\\n    Gracenote.ai, Melbourne Australia\\n2\\n    The Dickson Poon School of Law, King’s College London, United Kingdom*', metadata={}),\n",
              " Document(page_content='Abstract: We investigate the transformative potential of large language models\\n                                (LLMs) in the legal and regulatory compliance domain by developing advanced\\n                                generative AI solutions, including a horizon scanning tool, an obligations generation\\n                                tool, and an LLM-based expert system. Our approach combines the LangChain\\n                                framework, OpenAI’s GPT-4, text embeddings, and prompt engineering techniques\\n                                to effectively reduce hallucinations and generate reliable and accurate domain-\\n                                specific outputs. A human-in-the-loop control mechanism is used as a final backstop\\n                                to ensure accuracy and mitigate risk. Our findings emphasise the role of LLMs as\\n                                foundation engines in specialist tools and lay the groundwork for building the next\\n                                generation of legal and compliance applications. Future research will focus on\\n                                extending support across multiple jurisdictions and languages, refining prompts and\\n                                text embedding datasets for enhanced legal reasoning capabilities, and developing\\n                                autonomous AI agents and robust LLM-based expert systems.', metadata={}),\n",
              " Document(page_content='Keywords: AutoGPT, compliance, expert systems, GPT-4, GRC, LangChain, large\\n                                language models, legal generative AI, legal text embeddings, prompt engineering,\\n                                regulation\\n1', metadata={}),\n",
              " Document(page_content='LLMs are often called “foundation models”\\n1. Introduction                                                                                                because they can be used as a foundation to drive\\n                                                                                                               a range of products and services. This can be done\\n                                                                                                               in several ways, but the two standard approaches\\n   Law relies on language. So, it’s hardly                                                                     involve prompt engineering and fine-tuning. Fine-\\nsurprising that the development of large language\\n                                                                                                               tuning involves adapting a pre-trained LLM to a\\nmodels (LLMs) and the explosion of interest in                                                                 specific task or domain by training it on a\\npublicly accessible LLMs such as ChatGPT has\\n                                                                                                               specialised dataset, thus enhancing its relevance\\nled to the proliferation of papers about the use of                                                            and performance [11]. Although the providers of\\nthese kinds of models in law. These papers                                                                     LLMs will often create interfaces for users to fine-\\ninclude some general explorations of natural                                                                   tune the model, fine-tuning is relatively difficult\\nlanguage parsing and LLMs in law [1], [2], [3], as                                                             because it requires significant data and advanced\\nwell as a number looking at whether GPT can pass                                                               skills at controlling the dataset to tune the pre-\\nthe bar exam, law school exams, or other                                                                       trained model. A more common way of using\\nstandardised legal tests [4], [5], [6], [7], and [8].                                                          LLMs as a foundation engine is to use prompt\\nInevitably, there have been papers foretelling the                                                             engineering to constrain the output generated by\\ndeath of lawyers by LLMs [9], together with those\\n                                                                                                               the model.\\nwhich argue that the future of all professional\\nwork will be revolutionised by LLMs [10].                                                                         LLMs rely on user-generated prompts to\\n                                                                                                               provide both the context and the request that\\n                                                                                                               generates the output (often called the', metadata={})]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IczFCIKaLCet"
      },
      "source": [
        "##  3 types of CombineDocuments Chains\n",
        "\n",
        "[Taken from the LangChain Docs](https://langchain.readthedocs.io/en/latest/modules/indexes/combine_docs.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6kbcja8O7-Q"
      },
      "source": [
        "## Summarize Simple with map_reduce"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zr-AO5qlJNZ"
      },
      "source": [
        "### Map Reduce\n",
        "This method involves **an initial prompt on each chunk of data ***\n",
        "( for summarization tasks, this could be a summary of that chunk; for question-answering tasks, it could be an answer based solely on that chunk). **Then a different prompt is run to combine all the initial outputs.** This is implemented in the LangChain as the MapReduceDocumentsChain.\n",
        "\n",
        "**Pros:** Can scale to larger documents (and more documents) than StuffDocumentsChain. The calls to the LLM on individual documents are independent and can therefore be parallelized.\n",
        "\n",
        "**Cons:** Requires many more calls to the LLM than StuffDocumentsChain. Loses some information during the final combining call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "lFYz2IztO2nE"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.summarize import load_summarize_chain\n",
        "import textwrap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4nRP8oGO2qf",
        "outputId": "1b6f930e-6bf0-41b3-bee8-08409271ce22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  This article explores the potential of large language models (LLMs) to create advanced generative\n",
            "AI solutions for legal and regulatory compliance. LLMs have been used to explore natural language\n",
            "parsing, pass legal tests, and even replace lawyers. Technologies such as AutoGPT, GPT-4, LangChain,\n",
            "text embeddings, and prompt engineering are used to reduce hallucinations and generate reliable\n",
            "outputs. Future research focuses on extending support across multiple jurisdictions and languages,\n",
            "refining prompts, and developing autonomous AI agents.\n"
          ]
        }
      ],
      "source": [
        "chain = load_summarize_chain(llm,\n",
        "                             chain_type=\"map_reduce\")\n",
        "\n",
        "\n",
        "output_summary = chain.run(docs)\n",
        "wrapped_text = textwrap.fill(output_summary, width=100)\n",
        "print(wrapped_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "k0OK53Q3fReD",
        "outputId": "37a72505-6980-4d5a-a269-a0968e1276e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Write a concise summary of the following:\\n\\n\\n\"{text}\"\\n\\n\\nCONCISE SUMMARY:'"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# for summarizing each part\n",
        "chain.llm_chain.prompt.template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "L2JttqnWpR0H",
        "outputId": "03fe1f6d-16da-4cce-eb2d-247ebfb1de9d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Write a concise summary of the following:\\n\\n\\n\"{text}\"\\n\\n\\nCONCISE SUMMARY:'"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# for combining the parts\n",
        "chain.combine_document_chain.llm_chain.prompt.template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AUZ_e7MfsI1",
        "outputId": "b7551b05-a60d-4458-933b-ffb2354a0324"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\"Gracenote.ai: Legal Generative AI for Regulatory Compliance\n",
            "Jules Ioannidis, Joshua Harper, Ming Sheng Quah 1 and Dan Hunter 1, 2\n",
            "1\n",
            "    Gracenote.ai, Melbourne Australia\n",
            "2\n",
            "    The Dickson Poon School of Law, King’s College London, United Kingdom*\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\"Abstract: We investigate the transformative potential of large language models\n",
            "                                (LLMs) in the legal and regulatory compliance domain by developing advanced\n",
            "                                generative AI solutions, including a horizon scanning tool, an obligations generation\n",
            "                                tool, and an LLM-based expert system. Our approach combines the LangChain\n",
            "                                framework, OpenAI’s GPT-4, text embeddings, and prompt engineering techniques\n",
            "                                to effectively reduce hallucinations and generate reliable and accurate domain-\n",
            "                                specific outputs. A human-in-the-loop control mechanism is used as a final backstop\n",
            "                                to ensure accuracy and mitigate risk. Our findings emphasise the role of LLMs as\n",
            "                                foundation engines in specialist tools and lay the groundwork for building the next\n",
            "                                generation of legal and compliance applications. Future research will focus on\n",
            "                                extending support across multiple jurisdictions and languages, refining prompts and\n",
            "                                text embedding datasets for enhanced legal reasoning capabilities, and developing\n",
            "                                autonomous AI agents and robust LLM-based expert systems.\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\"Keywords: AutoGPT, compliance, expert systems, GPT-4, GRC, LangChain, large\n",
            "                                language models, legal generative AI, legal text embeddings, prompt engineering,\n",
            "                                regulation\n",
            "1\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\"LLMs are often called “foundation models”\n",
            "1. Introduction                                                                                                because they can be used as a foundation to drive\n",
            "                                                                                                               a range of products and services. This can be done\n",
            "                                                                                                               in several ways, but the two standard approaches\n",
            "   Law relies on language. So, it’s hardly                                                                     involve prompt engineering and fine-tuning. Fine-\n",
            "surprising that the development of large language\n",
            "                                                                                                               tuning involves adapting a pre-trained LLM to a\n",
            "models (LLMs) and the explosion of interest in                                                                 specific task or domain by training it on a\n",
            "publicly accessible LLMs such as ChatGPT has\n",
            "                                                                                                               specialised dataset, thus enhancing its relevance\n",
            "led to the proliferation of papers about the use of                                                            and performance [11]. Although the providers of\n",
            "these kinds of models in law. These papers                                                                     LLMs will often create interfaces for users to fine-\n",
            "include some general explorations of natural                                                                   tune the model, fine-tuning is relatively difficult\n",
            "language parsing and LLMs in law [1], [2], [3], as                                                             because it requires significant data and advanced\n",
            "well as a number looking at whether GPT can pass                                                               skills at controlling the dataset to tune the pre-\n",
            "the bar exam, law school exams, or other                                                                       trained model. A more common way of using\n",
            "standardised legal tests [4], [5], [6], [7], and [8].                                                          LLMs as a foundation engine is to use prompt\n",
            "Inevitably, there have been papers foretelling the                                                             engineering to constrain the output generated by\n",
            "death of lawyers by LLMs [9], together with those\n",
            "                                                                                                               the model.\n",
            "which argue that the future of all professional\n",
            "work will be revolutionised by LLMs [10].                                                                         LLMs rely on user-generated prompts to\n",
            "                                                                                                               provide both the context and the request that\n",
            "                                                                                                               generates the output (often called the\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\"\n",
            "Gracenote.ai is a legal generative AI developed to help organizations meet regulatory compliance. It was created by Jules Ioannidis, Joshua Harper, Ming Sheng Quah, and Dan Hunter of Gracenote.ai in Melbourne, Australia and King's College London in the United Kingdom.\n",
            "\n",
            " This paper investigates the potential of large language models (LLMs) for legal and regulatory compliance, developing AI solutions such as a horizon scanning tool, an obligations generation tool, and an LLM-based expert system. The approach combines LangChain, OpenAI's GPT-4, text embeddings, and prompt engineering techniques to reduce hallucinations and generate accurate domain-specific outputs. The findings emphasize LLMs as essential engines for specialist tools and lay the groundwork for building the next generation of legal and compliance applications. Future research will focus on extending support across multiple jurisdictions and languages, refining prompts and text embedding datasets, and developing autonomous AI agents and robust LLM-based expert systems.\n",
            "\n",
            "\n",
            "This article discusses the use of AI in legal compliance, specifically focusing on AutoGPT, GPT-4, LangChain, large language models, legal generative AI, legal text embeddings, prompt engineering, and regulation.\n",
            "\n",
            " LLMs (Large Language Models) are often used as a foundation to drive a range of products and services, usually through prompt engineering and fine-tuning. Fine-tuning involves adapting a pre-trained LLM to a specific task or domain by training it on a specialised dataset. Prompt engineering constrains the output generated by the model. There have been papers discussing the use of LLMs in law, predicting the death of lawyers by LLMs, and arguing that the future of all professional work will be revolutionised by LLMs.\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            " This article discusses the use of AI in legal compliance, specifically focusing on AutoGPT, GPT-4,\n",
            "LangChain, large language models, legal generative AI, legal text embeddings, prompt engineering,\n",
            "and regulation. It investigates the potential of large language models for legal and regulatory\n",
            "compliance, developing AI solutions such as a horizon scanning tool, an obligations generation tool,\n",
            "and an LLM-based expert system. It emphasizes LLMs as essential engines for specialist tools and\n",
            "lays the groundwork for building the next generation of legal and compliance applications.\n"
          ]
        }
      ],
      "source": [
        "chain = load_summarize_chain(llm,\n",
        "                             chain_type=\"map_reduce\",\n",
        "                             verbose=True\n",
        "                             )\n",
        "\n",
        "\n",
        "output_summary = chain.run(docs)\n",
        "wrapped_text = textwrap.fill(output_summary,\n",
        "                             width=100,\n",
        "                             break_long_words=False,\n",
        "                             replace_whitespace=False)\n",
        "print(wrapped_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6yiwXNnvzxO"
      },
      "source": [
        "### Summarizing with the 'stuff' Chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9o7FgrlMhuW2"
      },
      "source": [
        "\n",
        "\n",
        "### Stuffing\n",
        "Stuffing is the simplest method, whereby you simply stuff all the related data into the prompt as context to pass to the language model. This is implemented in LangChain as the StuffDocumentsChain.\n",
        "\n",
        "**Pros:** Only makes a single call to the LLM. When generating text, the LLM has access to all the data at once.\n",
        "\n",
        "**Cons:** Most LLMs have a context length, and for large documents (or many documents) this will not work as it will result in a prompt larger than the context length.\n",
        "\n",
        "The main downside of this method is that **it only works one smaller pieces of data.**  Once you are working with many pieces of data, this approach is no longer feasible. The next two approaches are designed to help deal with that.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "OzCHODNOPKnO"
      },
      "outputs": [],
      "source": [
        "chain = load_summarize_chain(llm, chain_type=\"stuff\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "XTMPc6oQPQr0"
      },
      "outputs": [],
      "source": [
        "prompt_template = \"\"\"Write a concise bullet point summary of the following:\n",
        "\n",
        "\n",
        "{text}\n",
        "\n",
        "\n",
        "CONSCISE SUMMARY IN BULLET POINTS:\"\"\"\n",
        "\n",
        "BULLET_POINT_PROMPT = PromptTemplate(template=prompt_template,\n",
        "                        input_variables=[\"text\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrtSb8VphVG-",
        "outputId": "8c59f9f3-9a3e-4c7a-a232-1dfc2394fde4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n",
            "- Gracenote.ai is a legal generative AI for regulatory compliance developed by Jules Ioannidis,\n",
            "Joshua Harper, Ming Sheng Quah and Dan Hunter\n",
            "- Combines LangChain framework, OpenAI’s GPT-4, text\n",
            "embeddings and prompt engineering techniques to reduce hallucinations and generate accurate outputs\n",
            "- Human-in-the-loop control mechanism used as a backstop to ensure accuracy and mitigate risk\n",
            "- LLMs\n",
            "used as foundation engines in specialist tools\n",
            "- Future research will focus on extending support\n",
            "across multiple jurisdictions and languages, refining prompts and text embedding datasets, and\n",
            "developing autonomous AI agents and robust LLM-based expert systems.\n"
          ]
        }
      ],
      "source": [
        "chain = load_summarize_chain(llm,\n",
        "                             chain_type=\"stuff\",\n",
        "                             prompt=BULLET_POINT_PROMPT)\n",
        "\n",
        "output_summary = chain.run(docs)\n",
        "\n",
        "wrapped_text = textwrap.fill(output_summary,\n",
        "                             width=100,\n",
        "                             break_long_words=False,\n",
        "                             replace_whitespace=False)\n",
        "print(wrapped_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ_ig4J_PYbm"
      },
      "source": [
        "### Ver 3 With 'map_reduce' with our custom prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lS7vYgKPcqV",
        "outputId": "e2824e48-6d27-4e1a-ba53-489574722574"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "- Gracenote.ai is a legal generative AI for regulatory compliance developed by Jules Ioannidis,\n",
            "Joshua Harper, Ming Sheng Quah and Dan Hunter, based in Melbourne, Australia and The Dickson Poon\n",
            "School of Law, King’s College London, United Kingdom\n",
            "- Uses LLMs, text embeddings, and prompt\n",
            "engineering techniques with a human-in-the-loop control mechanism to ensure accuracy and mitigate\n",
            "risk\n",
            "- AutoGPT and LangChain are two examples of legal generative AI used to create legal documents\n",
            "- Prompt engineering and fine-tuning are two standard approaches used to generate legal text\n"
          ]
        }
      ],
      "source": [
        "chain = load_summarize_chain(llm,\n",
        "                             chain_type=\"map_reduce\",\n",
        "                             map_prompt=BULLET_POINT_PROMPT,\n",
        "                             combine_prompt=BULLET_POINT_PROMPT)\n",
        "\n",
        "# chain.llm_chain.prompt= BULLET_POINT_PROMPT\n",
        "# chain.combine_document_chain.llm_chain.prompt= BULLET_POINT_PROMPT\n",
        "\n",
        "output_summary = chain.run(docs)\n",
        "wrapped_text = textwrap.fill(output_summary,\n",
        "                             width=100,\n",
        "                             break_long_words=False,\n",
        "                             replace_whitespace=False)\n",
        "print(wrapped_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUFsaodtPkl4",
        "outputId": "e49cc8b4-f081-43d8-b0b3-3257f1f6e5bf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "• Gracenote.ai is a legal generative AI for regulatory compliance developed by a team based in\n",
            "Melbourne, Australia and The Dickson Poon School of Law, King’s College London, United Kingdom. \n",
            "•\n",
            "AutoGPT is a legal generative AI that uses large language models, expert systems, and prompt\n",
            "engineering to generate legal text embeddings.\n",
            "• GPT-4 and LangChain are two of the most popular GRC\n",
            "(Governance, Risk, and Compliance) tools used to help organizations comply with regulations.\n",
            "• LLMs\n",
            "(Large Language Models) are often referred to as “foundation models” and can be used to drive a\n",
            "range of products and services.\n",
            "• Papers have been written exploring the use of LLMs in law,\n",
            "including whether GPT can pass the bar exam or other legal tests, as well as papers predicting the\n",
            "death of lawyers by LLMs.\n"
          ]
        }
      ],
      "source": [
        "# with a custom prompt\n",
        "prompt_template = \"\"\"Write a concise summary of the following:\n",
        "\n",
        "\n",
        "{text}\n",
        "\n",
        "\n",
        "CONSCISE SUMMARY IN BULLET POINTS:\"\"\"\n",
        "\n",
        "PROMPT = PromptTemplate(template=prompt_template,\n",
        "                        input_variables=[\"text\"])\n",
        "\n",
        "## with intermediate steps\n",
        "chain = load_summarize_chain(OpenAI(temperature=0),\n",
        "                             chain_type=\"map_reduce\",\n",
        "                             return_intermediate_steps=True,\n",
        "                             map_prompt=PROMPT,\n",
        "                             combine_prompt=PROMPT)\n",
        "\n",
        "output_summary = chain({\"input_documents\": docs}, return_only_outputs=True)\n",
        "wrapped_text = textwrap.fill(output_summary['output_text'],\n",
        "                             width=100,\n",
        "                             break_long_words=False,\n",
        "                             replace_whitespace=False)\n",
        "print(wrapped_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvksjoTytSCb",
        "outputId": "03bc2547-cb3c-45ad-e546-404993cf1f8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "•\n",
            "Gracenote.ai\n",
            "is a legal\n",
            "generative\n",
            "AI for\n",
            "regulatory\n",
            "compliance\n",
            "developed\n",
            "by Jules\n",
            "Ioannidis,\n",
            "Joshua\n",
            "Harper,\n",
            "Ming Sheng\n",
            "Quah, and\n",
            "Dan\n",
            "Hunter. \n",
            "•\n",
            "The team\n",
            "is based\n",
            "in\n",
            "Melbourne,\n",
            "Australia\n",
            "and The\n",
            "Dickson\n",
            "Poon\n",
            "School of\n",
            "Law,\n",
            "King’s\n",
            "College\n",
            "London,\n",
            "United\n",
            "Kingdom.\n",
            "•\n",
            "Gracenote.ai\n",
            "is\n",
            "designed\n",
            "to help\n",
            "lawyers\n",
            "and legal\n",
            "professionals\n",
            "automate\n",
            "the\n",
            "process of\n",
            "creating\n",
            "legal\n",
            "documents,\n",
            "saving\n",
            "time and\n",
            "money. \n",
            "•\n",
            "The AI is\n",
            "able to\n",
            "generate\n",
            "legal\n",
            "documents\n",
            "that are\n",
            "tailored\n",
            "to the\n",
            "specific\n",
            "needs of\n",
            "the user,\n",
            "ensuring\n",
            "accuracy\n",
            "and\n",
            "compliance\n",
            "with\n",
            "regulations.\n"
          ]
        }
      ],
      "source": [
        "wrapped_text = textwrap.fill(output_summary['intermediate_steps'][0],\n",
        "                             width=10,\n",
        "                             break_long_words=False,\n",
        "                             replace_whitespace=False)\n",
        "print(wrapped_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caaAmomfPv9j"
      },
      "source": [
        "### With the 'refine' CombineDocument Chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39P6zjy9lT5X"
      },
      "source": [
        "## Refine\n",
        "This method involves **an initial prompt on the first chunk of data, generating some output. For the remaining documents, that output is passed in, along with the next document**, asking the LLM to refine the output based on the new document.\n",
        "\n",
        "**Pros:** Can pull in more relevant context, and may be less lossy than MapReduceDocumentsChain.\n",
        "\n",
        "**Cons:** Requires many more calls to the LLM than StuffDocumentsChain. The calls are also NOT independent, meaning they cannot be paralleled like MapReduceDocumentsChain. There is also some potential dependencies on the ordering of the documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ji2D8Q0P2gh",
        "outputId": "cb493a3e-93f2-4fee-e6fc-4e4308e62aa4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Gracenote.ai is a legal generative AI for regulatory compliance developed by Jules Ioannidis,\n",
            "Joshua Harper, Ming Sheng Quah, and Dan Hunter from Gracenote.ai in Melbourne, Australia, and the\n",
            "Dickson Poon School of Law at King’s College London in the United Kingdom. The AI combines the\n",
            "LangChain framework, OpenAI’s GPT-4, text embeddings, AutoGPT, GRC, large language models (LLMs)\n",
            "often called “foundation models”, and prompt engineering techniques to effectively reduce\n",
            "hallucinations and generate reliable and accurate domain-specific outputs. It also features a human-\n",
            "in-the-loop control mechanism to ensure accuracy and mitigate risk. This AI lays the groundwork for\n",
            "building the next generation of legal and compliance applications, with future research focused on\n",
            "extending support across multiple jurisdictions and languages, refining prompts and text embedding\n",
            "datasets, and developing autonomous AI agents and robust LLM-based expert systems.\n"
          ]
        }
      ],
      "source": [
        "chain = load_summarize_chain(llm, chain_type=\"refine\")\n",
        "\n",
        "output_summary = chain.run(docs)\n",
        "wrapped_text = textwrap.fill(output_summary, width=100)\n",
        "print(wrapped_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "JsoM2yyoQNzF"
      },
      "outputs": [],
      "source": [
        "prompt_template = \"\"\"Write a concise summary of the following extracting the key information:\n",
        "\n",
        "\n",
        "{text}\n",
        "\n",
        "\n",
        "CONCISE SUMMARY:\"\"\"\n",
        "PROMPT = PromptTemplate(template=prompt_template,\n",
        "                        input_variables=[\"text\"])\n",
        "\n",
        "refine_template = (\n",
        "    \"Your job is to produce a final summary\\n\"\n",
        "    \"We have provided an existing summary up to a certain point: {existing_answer}\\n\"\n",
        "    \"We have the opportunity to refine the existing summary\"\n",
        "    \"(only if needed) with some more context below.\\n\"\n",
        "    \"------------\\n\"\n",
        "    \"{text}\\n\"\n",
        "    \"------------\\n\"\n",
        "    \"Given the new context, refine the original summary\"\n",
        "    \"If the context isn't useful, return the original summary.\"\n",
        ")\n",
        "refine_prompt = PromptTemplate(\n",
        "    input_variables=[\"existing_answer\", \"text\"],\n",
        "    template=refine_template,\n",
        ")\n",
        "chain = load_summarize_chain(OpenAI(temperature=0),\n",
        "                             chain_type=\"refine\",\n",
        "                             return_intermediate_steps=True,\n",
        "                             question_prompt=PROMPT,\n",
        "                             refine_prompt=refine_prompt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgIuOQWbfFep",
        "outputId": "6b701913-2b71-4652-cfa6-1e96f542ee20"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-xDjxK3O2naZzvtFMMChWhYwt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Gracenote.ai is a legal generative AI developed by Jules Ioannidis, Joshua Harper, Ming Sheng Quah\n",
            "and Dan Hunter from Gracenote.ai in Melbourne, Australia and The Dickson Poon School of Law at\n",
            "King's College London, United Kingdom. It combines the LangChain framework, OpenAI’s GPT-4, text\n",
            "embeddings, and prompt engineering techniques to effectively reduce hallucinations and generate\n",
            "reliable and accurate domain-specific outputs. The AutoGPT algorithm is used to generate legal text\n",
            "embeddings for GRC (Governance, Risk and Compliance) and large language models (LLMs) are used as a\n",
            "foundation to drive a range of products and services. This is done through prompt engineering and\n",
            "fine-tuning, which involves adapting a pre-trained LLM to a specific task or domain by training it\n",
            "on a specialised dataset. A human-in-the-loop control mechanism is used as a final backstop to\n",
            "ensure accuracy and mitigate risk, and future research will focus on extending support across\n",
            "multiple jurisdictions and languages, refining prompts and text embedding datasets for enhanced\n",
            "legal reasoning capabilities, and developing autonomous AI agents and robust LLM-based expert\n",
            "systems.\n"
          ]
        }
      ],
      "source": [
        "output_summary = chain({\"input_documents\": docs}, return_only_outputs=True)\n",
        "wrapped_text = textwrap.fill(output_summary['output_text'],\n",
        "                             width=100,\n",
        "                             break_long_words=False,\n",
        "                             replace_whitespace=False)\n",
        "print(wrapped_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dt7v2DVavMpX",
        "outputId": "eddfab8d-2731-492f-fc16-8d8c25d2aec8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Gracenote.ai is a legal generative AI developed by Jules Ioannidis, Joshua Harper, Ming Sheng Quah\n",
            "and Dan Hunter from Gracenote.ai in Melbourne, Australia and The Dickson Poon School of Law at\n",
            "King's College London, United Kingdom, designed to help with regulatory compliance.\n"
          ]
        }
      ],
      "source": [
        "wrapped_text = textwrap.fill(output_summary['intermediate_steps'][0],\n",
        "                             width=100,\n",
        "                             break_long_words=False,\n",
        "                             replace_whitespace=False)\n",
        "print(wrapped_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtEBpGcCRGzk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
